{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recogniser\n",
    "This is my code for digit recogniser competition \n",
    "My rank for in top 8% on the leaderbord at the time of submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n",
      "/kaggle/input/digit-recognizer/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_data['label']\n",
    "X=train_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.isnull(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image=X[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image=single_image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffb38699898>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(single_image[:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cat=to_categorical(y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test=to_categorical(y_test)\n",
    "y_cat_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0],cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Conv2D,Flatten,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,input_shape=(28,28,1),kernel_size=(5,5),activation='relu'))\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         zoom_range = 0.1, # Randomly zoom image \n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=False,  # randomly flip images\n",
    "#         vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.fit_generator((datagen.flow(X_train,y_cat_train, batch_size=16),epochs=1,\n",
    "#                               steps_per_epoch=150,\n",
    "#                               validation_data=(X_test,y_cat_test),\n",
    "#                              validation_steps=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_gen=ImageDataGenerator(rotation_range=30,\n",
    "#                             width_shift_range=0.1,\n",
    "#                             height_shift_range=0.1,\n",
    "#                             rescale=1/255,\n",
    "#                             shear_range=0.2,\n",
    "#                             zoom_range=0.2,\n",
    "#                             horizontal_flip=False,\n",
    "#                             vertical_flip=False,\n",
    "#                             fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image_gen.fit(X_train)\n",
    "# gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "#                          height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "# test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = gen.flow(X_train, y_cat_train, batch_size=64)\n",
    "# test_generator = test_gen.flow(X_test, y_cat_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(train_generator, steps_per_epoch=6, epochs=5, \n",
    "#                     validation_data=test_generator, validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_image_gen = image_gen.flow_from_dataframe((X_train,y_),\n",
    "#                                                target_size=image_shape[:2],\n",
    "#                                                batch_size=batch_size,\n",
    "#                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(monitor='val_accuracy',mode='min',verbose=1,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ln_fc = lambda x: 1e-3 * 0.985 ** x\n",
    "# lrng_rt = tf.keras.callbacks.LearningRateScheduler(ln_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 80\n",
    "# history = model.fit_generator(image_gen.flow(X_train,y_cat_train, batch_size=batch_size),\n",
    "#                               epochs = 5, validation_data = (X_test,y_cat_test),\n",
    "#                               verbose = 1, steps_per_epoch = X_train.shape[0]//batch_size,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "# batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         zoom_range = 0.1, # Randomly zoom image \n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=False,  # randomly flip images\n",
    "#         vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "# datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.4253 - accuracy: 0.8631 - val_loss: 0.0838 - val_accuracy: 0.9738\n",
      "Epoch 2/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.1237 - accuracy: 0.9618 - val_loss: 0.0787 - val_accuracy: 0.9719\n",
      "Epoch 3/100\n",
      "472/472 [==============================] - 72s 152ms/step - loss: 0.0903 - accuracy: 0.9723 - val_loss: 0.0394 - val_accuracy: 0.9888\n",
      "Epoch 4/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0692 - accuracy: 0.9788 - val_loss: 0.0267 - val_accuracy: 0.9902\n",
      "Epoch 5/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0613 - accuracy: 0.9814 - val_loss: 0.0465 - val_accuracy: 0.9848\n",
      "Epoch 6/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 0.0273 - val_accuracy: 0.9914\n",
      "Epoch 7/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.0248 - val_accuracy: 0.9931\n",
      "Epoch 8/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0472 - accuracy: 0.9853 - val_loss: 0.0313 - val_accuracy: 0.9912\n",
      "Epoch 9/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0424 - accuracy: 0.9876 - val_loss: 0.0237 - val_accuracy: 0.9926\n",
      "Epoch 10/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0390 - accuracy: 0.9881 - val_loss: 0.0269 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0283 - accuracy: 0.9920 - val_loss: 0.0245 - val_accuracy: 0.9919\n",
      "Epoch 12/100\n",
      "472/472 [==============================] - 71s 150ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0163 - val_accuracy: 0.9950\n",
      "Epoch 13/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0205 - val_accuracy: 0.9940\n",
      "Epoch 14/100\n",
      "472/472 [==============================] - 70s 148ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0226 - val_accuracy: 0.9950\n",
      "Epoch 15/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.0248 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 16/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0178 - val_accuracy: 0.9955\n",
      "Epoch 17/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0222 - val_accuracy: 0.9948\n",
      "Epoch 18/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0204 - val_accuracy: 0.9943\n",
      "Epoch 19/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0216 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 20/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0204 - val_accuracy: 0.9940\n",
      "Epoch 21/100\n",
      "472/472 [==============================] - 71s 150ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0193 - val_accuracy: 0.9948\n",
      "Epoch 22/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0208 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 23/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0201 - val_accuracy: 0.9950\n",
      "Epoch 24/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0199 - val_accuracy: 0.9945\n",
      "Epoch 25/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0199 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 26/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0194 - val_accuracy: 0.9950\n",
      "Epoch 27/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0194 - val_accuracy: 0.9950\n",
      "Epoch 28/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0200 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 29/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0194 - val_accuracy: 0.9950\n",
      "Epoch 30/100\n",
      "472/472 [==============================] - 70s 149ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
      "Epoch 31/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0192 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 32/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
      "Epoch 33/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0194 - val_accuracy: 0.9950\n",
      "Epoch 34/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0200 - val_accuracy: 0.9952\n",
      "Epoch 35/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0200 - val_accuracy: 0.9952\n",
      "Epoch 36/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0194 - val_accuracy: 0.9952\n",
      "Epoch 37/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0198 - val_accuracy: 0.9952\n",
      "Epoch 38/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0197 - val_accuracy: 0.9950\n",
      "Epoch 39/100\n",
      "472/472 [==============================] - 71s 150ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0192 - val_accuracy: 0.9950\n",
      "Epoch 40/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0197 - val_accuracy: 0.9955\n",
      "Epoch 41/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0197 - val_accuracy: 0.9952\n",
      "Epoch 42/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0193 - val_accuracy: 0.9952\n",
      "Epoch 43/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
      "Epoch 44/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0195 - val_accuracy: 0.9950\n",
      "Epoch 45/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0196 - val_accuracy: 0.9950\n",
      "Epoch 46/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0189 - val_accuracy: 0.9950\n",
      "Epoch 47/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0193 - val_accuracy: 0.9955\n",
      "Epoch 48/100\n",
      "472/472 [==============================] - 72s 152ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0188 - val_accuracy: 0.9952\n",
      "Epoch 49/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0190 - val_accuracy: 0.9952\n",
      "Epoch 50/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0190 - val_accuracy: 0.9950\n",
      "Epoch 51/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
      "Epoch 52/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0188 - val_accuracy: 0.9952\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0193 - val_accuracy: 0.9955\n",
      "Epoch 54/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0188 - val_accuracy: 0.9955\n",
      "Epoch 55/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0194 - val_accuracy: 0.9952\n",
      "Epoch 56/100\n",
      "472/472 [==============================] - 71s 150ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0188 - val_accuracy: 0.9955\n",
      "Epoch 57/100\n",
      "472/472 [==============================] - 69s 147ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0186 - val_accuracy: 0.9955\n",
      "Epoch 58/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0191 - val_accuracy: 0.9950\n",
      "Epoch 59/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0195 - val_accuracy: 0.9952\n",
      "Epoch 60/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0189 - val_accuracy: 0.9952\n",
      "Epoch 61/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0200 - val_accuracy: 0.9952\n",
      "Epoch 62/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0193 - val_accuracy: 0.9950\n",
      "Epoch 63/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0184 - val_accuracy: 0.9955\n",
      "Epoch 64/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
      "Epoch 65/100\n",
      "472/472 [==============================] - 70s 149ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0187 - val_accuracy: 0.9955\n",
      "Epoch 66/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0183 - val_accuracy: 0.9957\n",
      "Epoch 67/100\n",
      "472/472 [==============================] - 70s 147ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0185 - val_accuracy: 0.9955\n",
      "Epoch 68/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0188 - val_accuracy: 0.9955\n",
      "Epoch 69/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0189 - val_accuracy: 0.9957\n",
      "Epoch 70/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0188 - val_accuracy: 0.9952\n",
      "Epoch 71/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0190 - val_accuracy: 0.9955\n",
      "Epoch 72/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0187 - val_accuracy: 0.9957\n",
      "Epoch 73/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0186 - val_accuracy: 0.9955\n",
      "Epoch 74/100\n",
      "472/472 [==============================] - 71s 150ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0187 - val_accuracy: 0.9955\n",
      "Epoch 75/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0195 - val_accuracy: 0.9952\n",
      "Epoch 76/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0193 - val_accuracy: 0.9955\n",
      "Epoch 77/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0192 - val_accuracy: 0.9955\n",
      "Epoch 78/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0191 - val_accuracy: 0.9957\n",
      "Epoch 79/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0192 - val_accuracy: 0.9960\n",
      "Epoch 80/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0199 - val_accuracy: 0.9960\n",
      "Epoch 81/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0190 - val_accuracy: 0.9960\n",
      "Epoch 82/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0190 - val_accuracy: 0.9962\n",
      "Epoch 83/100\n",
      "472/472 [==============================] - 71s 150ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0192 - val_accuracy: 0.9960\n",
      "Epoch 84/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0187 - val_accuracy: 0.9962\n",
      "Epoch 85/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0195 - val_accuracy: 0.9957\n",
      "Epoch 86/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0186 - val_accuracy: 0.9960\n",
      "Epoch 87/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0184 - val_accuracy: 0.9962\n",
      "Epoch 88/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
      "Epoch 89/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0186 - val_accuracy: 0.9960\n",
      "Epoch 90/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0183 - val_accuracy: 0.9962\n",
      "Epoch 91/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0188 - val_accuracy: 0.9962\n",
      "Epoch 92/100\n",
      "472/472 [==============================] - 71s 150ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0192 - val_accuracy: 0.9960\n",
      "Epoch 93/100\n",
      "472/472 [==============================] - 68s 144ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0185 - val_accuracy: 0.9967\n",
      "Epoch 94/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0187 - val_accuracy: 0.9960\n",
      "Epoch 95/100\n",
      "472/472 [==============================] - 69s 146ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0186 - val_accuracy: 0.9962\n",
      "Epoch 96/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0181 - val_accuracy: 0.9960\n",
      "Epoch 97/100\n",
      "472/472 [==============================] - 68s 145ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0185 - val_accuracy: 0.9960\n",
      "Epoch 98/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0191 - val_accuracy: 0.9960\n",
      "Epoch 99/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0188 - val_accuracy: 0.9960\n",
      "Epoch 100/100\n",
      "472/472 [==============================] - 69s 145ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0185 - val_accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train,y_cat_train, batch_size=batch_size),\n",
    "                              epochs = 100, validation_data = (X_test,y_cat_test),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              ,callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train,y_cat_train,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('DigitGen1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       422\n",
      "           1       1.00      1.00      1.00       473\n",
      "           2       1.00      1.00      1.00       409\n",
      "           3       1.00      0.99      1.00       426\n",
      "           4       0.99      1.00      0.99       429\n",
      "           5       1.00      1.00      1.00       382\n",
      "           6       1.00      1.00      1.00       412\n",
      "           7       0.99      1.00      1.00       469\n",
      "           8       0.99      1.00      1.00       384\n",
      "           9       1.00      0.99      0.99       394\n",
      "\n",
      "    accuracy                           1.00      4200\n",
      "   macro avg       1.00      1.00      1.00      4200\n",
      "weighted avg       1.00      1.00      1.00      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 9, ..., 9, 3, 7])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results=np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       6\n",
       "2       9\n",
       "3       5\n",
       "4       6\n",
       "       ..\n",
       "4195    8\n",
       "4196    4\n",
       "4197    9\n",
       "4198    3\n",
       "4199    7\n",
       "Name: Label, Length: 4200, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        0\n",
       "2        9\n",
       "3        0\n",
       "4        3\n",
       "        ..\n",
       "27995    9\n",
       "27996    7\n",
       "27997    3\n",
       "27998    9\n",
       "27999    2\n",
       "Name: Label, Length: 28000, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = np.argmax(predictions,axis = 1)\n",
    "\n",
    "# results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      0\n",
       "1        2      0\n",
       "2        3      0\n",
       "3        4      0\n",
       "4        5      0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.predict(test_data)\n",
    "# results = np.argmax(results,axis = 1)\n",
    "# results = pd.Series(results,name=\"Label\")\n",
    "\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"nn_mnist.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      0\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
